MODEL_NAME="Meta-Llama-3.1-405B-Instruct"
MODEL_TYPE="OLLAMA" # if use the gpt series (OpenAI), lamma series (LLAMA)
OPENAI_API_KEY="b0fadda0-1162-4576-bd78-7d2c9b07d331"
OPENAI_ORGANIZATION=""
# API_BASE_URL="http://127.0.0.1:8079" # turn it on if using a VPN
OPENAI_BASE_URL="https://api.chatanywhere.tech"

# BING_SUBSCRIPTION_KEY=""
# BING_SEARCH_URL="https://api.bing.microsoft.com/v7.0/search"
# WOLFRAMALPHA_APP_ID=""

# LLAMA in local server
# open llama3 at local server
# curl -fsSL https://ollama.com/install.sh | sh
# ollama run llama3
# export NO_PROXY=localhost,127.0.0.1
# MODEL_NAME="llama3"
MODEL_TYPE="OLLAMA"
EMBED_MODEL_TYPE="OLLAMA"
EMBED_MODEL_NAME="Meta-Llama-3.1-405B-Instruct"
MODEL_SERVER="https://api.sambanova.ai/v1/chat/completions" # only for local model

